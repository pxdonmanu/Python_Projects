{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT PYHTON MACHINE LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Data Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "  NEGATIVE=\"NEGATIVE\"\n",
    "  NEUTRAL=\"NEUTRAL\"\n",
    "  POSITIVE=\"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "  def __init__(self, text, score):\n",
    "    self.text=text\n",
    "    self.score=score\n",
    "    self.sentiment=self.get_sentiment()\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    if self.score<=2:\n",
    "      return Sentiment.NEGATIVE\n",
    "    elif self.score==3:\n",
    "      return Sentiment.NEUTRAL\n",
    "    else: # Score of 4 or 5\n",
    "      return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "  def __init__(self, reviews):\n",
    "    self.reviews=reviews\n",
    "\n",
    "  def get_text(self):\n",
    "    return [x.text for x in self.reviews]\n",
    "\n",
    "  def get_sentiment(self):\n",
    "    return [x.sentiment for x in self.reviews]\n",
    "\n",
    "  def evenly_distribute(self):\n",
    "    negative=list(filter(lambda x: x.sentiment==Sentiment.NEGATIVE, self.reviews))\n",
    "    positive=list(filter(lambda x: x.sentiment==Sentiment.POSITIVE, self.reviews))\n",
    "    positive_shrunk=positive[:len(negative)]\n",
    "    self.reviews=negative+positive_shrunk\n",
    "    random.shuffle(self.reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the First book in the Trilogy, and I'm looking forward to reading the second book.  I liked how the main characters interacted with famous characters in western history.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name='./Books_Data_10000.json'\n",
    "\n",
    "# Array to store the reviews\n",
    "reviews=[]\n",
    "\n",
    "# With is used to open and close the file automatically and for loop is used to read the file line by line, and the letter f is used to represent the file\n",
    "with open(file_name) as f:\n",
    "  for line in f:\n",
    "    # print(line)\n",
    "    ## json.loads() converts a text string in json format to a python object\n",
    "    review=json.loads(line)\n",
    "    # print(f\"Reviewer Text: {review['reviewText']}\")\n",
    "    # print(f\"Overall: {review['overall']}\")\n",
    "    reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "# Review with reviewerText and overall\n",
    "# print(reviews[7])\n",
    "\n",
    "# If only I would like to know the reviewerText\n",
    "print(reviews[7].text)\n",
    "\n",
    "# If only I would like to know the overall\n",
    "print(reviews[7].score)\n",
    "\n",
    "# Know the sentiment based on the overall\n",
    "print(reviews[7].sentiment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reviews)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This line of code is used to split the data into training and test data\n",
    "training,test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container=ReviewContainer(training)\n",
    "test_container=ReviewContainer(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "6700\n"
     ]
    }
   ],
   "source": [
    "# The data that will be used for testing\n",
    "print(len(test))\n",
    "\n",
    "# The data that will be used for training\n",
    "print(len(training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivia Hampton arrives at the Dunraven family home as cataloger of their extensive library. What she doesn't expect is a broken carriage wheel on the way. Nor a young girl whose mind is clearly gone, an old man in need of care himself (and doesn&#8217;t quite seem all there in Olivia&#8217;s opinion). Furthermore, Marion Dunraven, the only sane one of the bunch and the one Olivia is inexplicable drawn to, seems captive to everyone in the dusty old house. More importantly, she doesn't expect to fall in love with Dunraven's daughter Marion.Can Olivia truly believe the stories of sadness and death that surround the house, or are they all just local neighborhood rumor?Was that carriage trouble just a coincidence or a supernatural sign to stay away? If she remains, will the Castle&#8217;s dark shadows take Olivia down with them or will she and Marion long enough to declare their love?Patty G. Henderson has created an atmospheric and intriguing story in her Gothic tale. I found this to be an enjoyable read, even if it isn&#8217;t my usual preferred genre. I think, with this tale, I got hooked on the old Gothic romantic style. So I think fans of the genre (and of lesbian romances) will enjoy it.\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(training[0].text)\n",
    "print(training[0].score)\n",
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soup..Er..Myrtle. Ms. Myrlte was talking to her dog Mtlock when Bettie Easton called. She called about the M.E.L.O.N.S (the letters stand for Mature Elegant Ladies Open Nice Suggestion) The first time she told me about it, I said it made us sound like old hookers.Bettie had been right about one thing.Doris Phillips met me at the door of the Soup kitchen just tickld pink to have a little help.Myrtle had discovered a identity theft ring but did not know who was doing it.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# This book is great!\n",
    "# This book was so bad\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x) \n",
    "\n",
    "test_x_vectors=vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "+ Linear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Linear Kernel\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "\n",
    "# Fit the data\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "test_x[0]\n",
    "test_x_vectors[0]\n",
    "\n",
    "test_x[0]\n",
    "\n",
    "# Predict the sentiment\n",
    "clf_svm.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec=DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Native Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb=GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0].toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log=LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6490384615384616\n",
      "0.6610576923076923\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracy\n",
    "\n",
    "# Evaluate the model with the score and the svm model\n",
    "eva_svm=clf_svm.score(test_x_vectors, test_y)\n",
    "\n",
    "# Evaluate the model with the score and the decision tree model\n",
    "eva_dec=clf_dec.score(test_x_vectors, test_y)\n",
    "\n",
    "# Evaluate the model with the score and the naive bayes model\n",
    "eva_gnb=clf_gnb.score(test_x_vectors.toarray(), test_y)\n",
    "\n",
    "# Evaluate the model with the score and the logistic regression model\n",
    "eva_log=clf_log.score(test_x_vectors, test_y)\n",
    "\n",
    "print(eva_svm)\n",
    "print(eva_dec)\n",
    "print(eva_gnb)\n",
    "print(eva_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8028169  0.79310345]\n",
      "[0.64470588 0.62899263]\n",
      "[0.59574468 0.66666667]\n",
      "[0.82051282 0.808933  ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# It predicts the general sentiment of the review\n",
    "f1_svm=f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "\n",
    "f1_dec=f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "\n",
    "f1_gnb=f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "\n",
    "f1_log=f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "\n",
    "print(f1_svm)\n",
    "print(f1_dec)\n",
    "print(f1_gnb)\n",
    "print(f1_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_y.count(Sentiment.POSITIVE))\n",
    "print(test_y.count(Sentiment.NEGATIVE))\n",
    "print(test_y.count(Sentiment.NEUTRAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set=['I thoroughly enjoyed this, 5 stars', 'it was very bored', 'very fun']\n",
    "new_test=vectorizer.transform(test_set)\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
